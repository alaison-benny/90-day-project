# **Diffrent types of terraform files**
**Main	.tf file, Variables	.tf, Output	.tf, State File	.tfstate file, Lock File	.hcl file**
# 1. main.tf (പ്രധാന ഫയൽ)
ഇതാണ് Terraform-ന്റെ ഹൃദയം. നിങ്ങൾക്ക് എന്തൊക്കെ റിസോഴ്‌സുകൾ വേണമെന്ന് ഇതിലാണ് എഴുതുന്നത്.
ഉദാഹരണം: ML മോഡൽ ട്രെയിൻ ചെയ്യാൻ ഒരു AWS SageMaker നോട്ട്ബുക്കോ അല്ലെങ്കിൽ ഒരു EC2 GPU ഇൻസ്റ്റൻസോ വേണമെന്ന് നിങ്ങൾ ഇതിൽ പറയും.        
# 2. variables.tf (വേരിയബിൾ ഫയൽ)
കോഡിനുള്ളിൽ നേരിട്ട് വാല്യൂകൾ നൽകാതെ (Hardcoding), അവയെ മാറ്റി നിർത്താൻ ഇത് സഹായിക്കുന്നു.
ഉദാഹരണം: പരീക്ഷണ ഘട്ടത്തിൽ (Dev) ചെറിയ സെർവറും, ശരിക്കുള്ള ഉപയോഗത്തിന് (Prod) വലിയ സെർവറും വേണമെങ്കിൽ, കോഡ് മാറ്റാതെ ഈ ഫയലിലെ വാല്യൂ മാത്രം മാറ്റിയാൽ മതി.
ML Context: മോഡൽ ട്രെയിനിംഗിന് ആവശ്യമായ instance_type (ഉദാ: p3.2xlarge) ഇവിടെ ഡിഫൈൻ ചെയ്യാം.
# 3. outputs.tf (ഔട്ട്‌പുട്ട് ഫയൽ)
ഇൻഫ്രാസ്ട്രക്ചർ നിർമ്മിച്ച് കഴിഞ്ഞാൽ നമുക്ക് ആവശ്യമായ ചില വിവരങ്ങൾ ഇത് കാണിച്ചുതരും.
ഉദാഹരണം: നിങ്ങൾ ഒരു ML മോഡൽ ഹോസ്റ്റ് ചെയ്യാൻ ഒരു എൻഡ്-പോയിന്റ് ഉണ്ടാക്കി. ആ ലിങ്ക് (URL) എന്താണെന്ന് ഔട്ട്‌പുട്ടിലൂടെ കാണാം.
Use Case: അടുത്ത ഘട്ടത്തിൽ ഡാറ്റാ സയന്റിസ്റ്റിന് ആ ലിങ്ക് കൈമാറാൻ ഇത് സഹായിക്കുന്നു
# 4. terraform.tfstate (സ്റ്റേറ്റ് ഫയൽ)
നിങ്ങൾ terraform apply ചെയ്യുമ്പോൾ ക്ലൗഡിൽ എന്തൊക്കെ മാറ്റങ്ങൾ വന്നു എന്ന് Terraform കുറിച്ചു വെക്കുന്ന ഡയറിയാണിത്. ഇത് ഒരിക്കലും കൈകൊണ്ട് എഡിറ്റ് ചെയ്യാൻ പാടില്ല.
ML Context: ഒരാൾ ഒരു GPU സർവർ നിർമ്മിച്ചു, മറ്റൊരാൾ അത് ഡിലീറ്റ് ചെയ്യാൻ ശ്രമിച്ചാൽ Terraform ഈ ഫയൽ നോക്കി അത് തടയുകയോ അറിയിക്കുകയോ ചെയ്യും.
# നിങ്ങൾ ശ്രദ്ധിക്കേണ്ട പ്രധാന കാര്യം:
ഒരു ML പ്ലാറ്റ്‌ഫോം എൻജിനീയർ എന്ന നിലയിൽ, ഈ ഫയലുകൾ ഒരു Git Repository-ൽ (GitHub/GitLab) സൂക്ഷിക്കണം.
ഒരു പ്രൊഡക്ഷൻ-ഗ്രേഡ് (Production Grade) ജനറേറ്റീവ് AI ആപ്ലിക്കേഷൻ (ChatGPT പോലുള്ളവ) നിർമ്മിക്കുമ്പോൾ, വെറുമൊരു സെർവർ ഉണ്ടാക്കുന്നത് പോലെയല്ല കാര്യങ്ങൾ. ഇതിന് ഉയർന്ന സുരക്ഷയും, പെർഫോമൻസും, ചെലവ് നിയന്ത്രിക്കാനുള്ള സംവിധാനങ്ങളും ആവശ്യമാണ്.

# **ഒരു `main.tf` ഫയലിൽ ഉൾപ്പെടുത്തേണ്ട പ്രധാന കാര്യങ്ങൾ താഴെ പറയുന്നവയാണ്:**

---

### 1. Provider and Backend Configuration (അടിസ്ഥാന സജ്ജീകരണം)

ആദ്യം ഏത് ക്ലൗഡ് (AWS, Azure, GCP) ആണ് ഉപയോഗിക്കുന്നത് എന്ന് വ്യക്തമാക്കണം. പ്രൊഡക്ഷൻ ആയതുകൊണ്ട് തന്നെ `State File` സ്വന്തം കമ്പ്യൂട്ടറിൽ വെക്കാതെ ക്ലൗഡിൽ (S3 Bucket) സൂക്ഷിക്കണം.

* **ഉപയോഗം:** ഒന്നിലധികം എൻജിനീയർമാർക്ക് ഒരേസമയം ജോലി ചെയ്യാനും ഡാറ്റ നഷ്ടപ്പെടാതിരിക്കാനും.

### 2. VPC & Networking (സുരക്ഷിതമായ ശൃംഖല)

ChatGPT പോലുള്ള ആപ്പുകൾക്ക് വലിയ തോതിലുള്ള ഡാറ്റ കൈമാറ്റം ആവശ്യമാണ്. അതിനാൽ ഒരു ക്ലൗഡ് നെറ്റ്‌വർക്ക് (VPC) നിർമ്മിക്കണം.

* **Public Subnet:** പുറംലോകത്തിന് ആപ്പ് കാണാൻ (Load Balancer).
* **Private Subnet:** AI മോഡലുകൾ റൺ ചെയ്യുന്ന സെർവറുകൾ ഇവിടെയായിരിക്കണം. ഇത് പുറത്തുനിന്നുള്ള ഹാക്കിംഗിൽ നിന്ന് സംരക്ഷണം നൽകുന്നു.

### 3. Compute Resources - GPU Instances (കമ്പ്യൂട്ടിംഗ് പവർ)

Generative AI-ക്ക് സാധാരണ CPU പോരാ, NVIDIA A100 അല്ലെങ്കിൽ H100 പോലുള്ള **GPU** സർവറുകൾ വേണം.

* **Auto Scaling Group:** തിരക്കുള്ള സമയത്ത് കൂടുതൽ സർവറുകൾ താനേ വരാനും, തിരക്ക് കുറയുമ്പോൾ അവ ഓഫ് ആകാനും ഇത് സഹായിക്കുന്നു.

### 4. IAM Roles & Security Groups (സുരക്ഷാ കവചം)

ആർക്കൊക്കെ ഡാറ്റ കാണാം, ഏതൊക്കെ പോർട്ടുകൾ തുറന്നിടണം എന്ന് ഇതിൽ തീരുമാനിക്കുന്നു.

* **Principle of Least Privilege:** ആവശ്യത്തിന് മാത്രം അനുവാദം നൽകുക. ഉദാഹരണത്തിന്, AI മോഡലിന് ഡാറ്റ റീഡ് ചെയ്യാൻ മാത്രം അനുവാദം നൽകുക, ഡിലീറ്റ് ചെയ്യാൻ നൽകരുത്.

### 5. Storage for Models (മോഡൽ സൂക്ഷിക്കാൻ)

ഭീമമായ വലിപ്പമുള്ള AI മോഡലുകൾ (Weights) സൂക്ഷിക്കാൻ S3 പോലുള്ള ഒബ്ജക്റ്റ് സ്റ്റോറേജ് വേണം.

* **Versioning:** മോഡലിന്റെ പുതിയ വേർഷൻ വരുമ്പോൾ പഴയത് നഷ്ടപ്പെടാതെ സൂക്ഷിക്കാൻ ഇത് സഹായിക്കുന്നു.

### 6. Monitoring & Logging (നിരീക്ഷണം)

സിസ്റ്റം തകരാറിലായാൽ ഉടൻ അറിയാൻ CloudWatch പോലുള്ള സർവീസുകൾ കണക്ട് ചെയ്യണം.

---

### ഒരു റിയൽ വേൾഡ് കമ്പനി ഉദാഹരണം (Example: OpenAI/Anthropic)

നിങ്ങൾ ഒരു ChatGPT പോലുള്ള ആപ്പ് ലോഞ്ച് ചെയ്യുന്നു എന്ന് കരുതുക:

1. **പ്രശ്നം:** പെട്ടെന്ന് പത്ത് ലക്ഷം ആളുകൾ ഒരേ സമയം ആപ്പ് ഉപയോഗിക്കാൻ വന്നാൽ സിസ്റ്റം ഡൗൺ ആകും.
2. **Terraform പരിഹാരം:** നിങ്ങളുടെ `main.tf`-ൽ ഒരു **Load Balancer** സെറ്റ് ചെയ്യുന്നു. ഇത് വരുന്ന ട്രാഫിക്കിനെ പല സെർവറുകളിലേക്ക് വീതിച്ചു നൽകുന്നു.
3. **ചെലവ് കുറയ്ക്കാൻ:** `main.tf`-ൽ **Spot Instances** ഉപയോഗിക്കാം. ഇത് സാധാരണ സർവറുകളേക്കാൾ 70-90% കുറഞ്ഞ നിരക്കിൽ ലഭിക്കും (നോൺ-ക്രിട്ടിക്കൽ ജോലികൾക്ക്).

---

### ഒരു ലളിതമായ `main.tf` ഘടന (Skeleton)

```hcl
# 1. Provider സെറ്റ് ചെയ്യുന്നു
provider "aws" {
  region = "us-east-1"
}

# 2. VPC നിർമ്മിക്കുന്നു
resource "aws_vpc" "ai_vpc" {
  cidr_block = "10.0.0.0/16"
}

# 3. AI മോഡൽ സൂക്ഷിക്കാനുള്ള സ്റ്റോറേജ്
resource "aws_s3_bucket" "model_storage" {
  bucket = "my-gen-ai-models-prod"
}

# 4. GPU സെർവർ (EC2)
resource "aws_instance" "gpu_server" {
  ami           = "ami-xxxxxx" 
  instance_type = "p3.2xlarge" # GPU ഉള്ള ഇൻസ്റ്റൻസ്
}

```

### നിങ്ങൾ ചെയ്യേണ്ട അടുത്ത പടി:

ഒരു പ്രൊഡക്ഷൻ ഫയലിൽ **Hardcode** ചെയ്യാൻ പാടില്ല (ഉദാഹരണത്തിന് പാസ്‌വേഡുകൾ നേരിട്ട് എഴുതരുത്). 
